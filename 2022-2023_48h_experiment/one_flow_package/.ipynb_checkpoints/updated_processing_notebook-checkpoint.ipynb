{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9429456e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T11:52:05.630744Z",
     "iopub.status.busy": "2023-11-08T11:52:05.630330Z",
     "iopub.status.idle": "2023-11-08T11:52:05.639469Z",
     "shell.execute_reply": "2023-11-08T11:52:05.638511Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./modules\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6834b5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T11:52:05.643876Z",
     "iopub.status.busy": "2023-11-08T11:52:05.643297Z",
     "iopub.status.idle": "2023-11-08T11:52:05.917692Z",
     "shell.execute_reply": "2023-11-08T11:52:05.916114Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nansat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import general modules\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnansat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Nansat, Domain, NSR\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Import temporal modules needed for testing plotting\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nansat'"
     ]
    }
   ],
   "source": [
    "# Import general modules\n",
    "from nansat import Nansat, Domain, NSR\n",
    "import os \n",
    "\n",
    "# Import temporal modules needed for testing plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Import SAR forecasting modules\n",
    "import config\n",
    "import s1_preparation\n",
    "import domains_preparation\n",
    "import SAR1_SAR2_drift_retrivial\n",
    "import warping_with_domain\n",
    "\n",
    "# Import variables\n",
    "from config import path_to_HH_files, path_to_HV_files, safe_folder \n",
    "from config import output_folder, input_folder\n",
    "from config import S1_prod_regex, S1_safe_regex\n",
    "from config import lon, lat, X, Y, proj4, srs\n",
    "\n",
    "# For cleaning up memory\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28eeefbd-e6c3-4bce-bc20-4d1a0fb8b528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair 1:\n",
      "SAR1: S1A_EW_GRDM_1SDH_20221120T080155_20221120T080259_045975_05805E_51E1.SAFE \n",
      "timestamp: 2022-11-20 08:01:55\n",
      "SAR2: S1A_EW_GRDM_1SDH_20221122T074535_20221122T074639_046004_05816B_9FC9.SAFE \n",
      "timestamp: 2022-11-22 07:45:35\n",
      "Pair 2:\n",
      "SAR1: S1A_EW_GRDM_1SDH_20230212T080151_20230212T080255_047200_05A9D0_C7EB.SAFE \n",
      "timestamp: 2023-02-12 08:01:51\n",
      "SAR2: S1A_EW_GRDM_1SDH_20230214T074531_20230214T074635_047229_05AAC8_4014.SAFE \n",
      "timestamp: 2023-02-14 07:45:31\n"
     ]
    }
   ],
   "source": [
    "# 1. Prepare SAR pairs\n",
    "\n",
    "# Collect Sentinel SAFE objects for files in safe directory.\n",
    "safe_objects = s1_preparation.collect_sentinel_files(safe_folder, path_to_HH_files, path_to_HV_files,  S1_safe_regex, S1_prod_regex)\n",
    "\n",
    "# Get pairs of Sentinel SAFE objects where their timestamps are within 50 hours of each other.\n",
    "sar_pairs = s1_preparation.get_pairs_within_time_limit(safe_objects, hours = 50)\n",
    "\n",
    "# Print details for each pair.\n",
    "for index, pair in enumerate(sar_pairs, start=1):  # start=1 makes the index start from 1\n",
    "    print(f'Pair {index}:')\n",
    "    print(f'SAR1: {pair[0].filename} \\ntimestamp: {pair[0].timestamp}\\n'\n",
    "          f'SAR2: {pair[1].filename} \\ntimestamp: {pair[1].timestamp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb6ccdd0-3680-47e3-8348-feb283662131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VMIN:  -3.9498636960983275\n",
      "VMAX:  5.663959283828735\n",
      "VMIN:  -3.5571017265319824\n",
      "VMAX:  5.484246134757996\n",
      "Successfully created /home/jovyan/experiment_data/2022-2023_48h_experiment/batch_output/20230212T080151_20230214T074531\n",
      "Successfully created /home/jovyan/experiment_data/2022-2023_48h_experiment/batch_output/20230212T080151_20230214T074531/HV_plots\n",
      "VMIN:  -3.774366235733032\n",
      "VMAX:  5.102492332458496\n",
      "VMIN:  -3.0308663845062256\n",
      "VMAX:  4.180728316307068\n",
      "Successfully created /home/jovyan/experiment_data/2022-2023_48h_experiment/batch_output/20230212T080151_20230214T074531\n",
      "Successfully created /home/jovyan/experiment_data/2022-2023_48h_experiment/batch_output/20230212T080151_20230214T074531/HH_plots\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Loop over all pairs and use enumerate to get an index for each pair\n",
    "for index, pair in enumerate(sar_pairs, start=1):  # start=1 to have human-friendly indexing\n",
    "    # Prepare nansat objects and domains for HV polarisation\n",
    "    n1_hv, n2_hv, output_dir_name_hv, plots_dir_hv = domains_preparation.prepare_nansat_objects(\n",
    "        pair[0], pair[1], output_folder, polarisation='HV', index=index)\n",
    "    \n",
    "    # Prepare nansat objects and domains for HH polarisation\n",
    "    n1_hh, n2_hh, output_dir_name_hh, plots_dir_hh = domains_preparation.prepare_nansat_objects(\n",
    "        pair[0], pair[1], output_folder, polarisation='HH', index=index)\n",
    "    \n",
    "    # Here you would include any additional processing steps for the SAR data\n",
    "    # And potentially save the results using the uniquely named output directories\n",
    "\n",
    "    # Additional processing steps\n",
    "    # 2.2  Define model domain (mod_dom) for comparing drift and comparison (dst_dom) domain to compare SAR images (real and forecasted)\n",
    "    \n",
    "    # Prepare subset model grid for domains and pattern matching\n",
    "    X_subset, Y_subset, lon_subset, lat_subset = domains_preparation.prepare_grid(n1_hv, n2_hv, srs, X, Y, lon, lat, buffer=0)\n",
    "    \n",
    "    # Set a model domain\n",
    "    mod_res = 2500\n",
    "    mod_dom = Domain(srs, f'-te {min(X_subset.data)} {min(Y_subset.data) - mod_res * 2} {max(X_subset.data) + mod_res} {max(Y_subset.data)} -tr {mod_res} {mod_res}')\n",
    "    \n",
    "    \n",
    "    lon1pm, lat1pm = mod_dom.get_geolocation_grids()\n",
    "    x, y = mod_dom.get_geolocation_grids(dst_srs=srs)\n",
    "    \n",
    "    # Set a comparison domain \n",
    "    dst_res = 100\n",
    "    dst_dom = Domain(srs, f'-te {min(X_subset.data)} {min(Y_subset.data) - dst_res * 2} {max(X_subset.data) + dst_res} {max(Y_subset.data)} -tr {dst_res} {dst_res}')\n",
    "    \n",
    "    domains_preparation.plot_borders(mod_dom, n1_hv, n2_hv, output_dir_name) # borders for hh and hv are the same\n",
    "    # Checking that domains have the same borders \n",
    "    \n",
    "    rows1, cols1 = dst_dom.shape()\n",
    "    print(\"dst_dom corner coordinates:\", dst_dom.transform_points([0,cols1-1,0,cols1-1], [0,0,rows1-1,rows1-1], dst_srs=srs))\n",
    "    \n",
    "    rows1, cols1 = mod_dom.shape()\n",
    "    print(\"mod_dom corner coordinates:\", mod_dom.transform_points([0,cols1-1,0,cols1-1], [0,0,rows1-1,rows1-1], dst_srs=srs))\n",
    "    # 3.   Retrieve reference drift\n",
    "    # 3.1. Run feature tracking and pattern matching for HV\n",
    "    \n",
    "    # Run feature tracking and plot results \n",
    "    c1_hv, r1_hv, c2_hv, r2_hv = SAR1_SAR2_drift_retrivial.run_feature_tracking(n1_hv, n2_hv, plots_dir_hv)\n",
    "    \n",
    "    #Run pattern matching and plot results\n",
    "    upm_hv, vpm_hv, apm_hv, rpm_hv, hpm_hv, ssim_hv, lon2pm_hv, lat2pm_hv = SAR1_SAR2_drift_retrivial.run_pattern_matching(plots_dir_hv, x, y, \n",
    "                                                               lon1pm, lat1pm, n1_hv, c1_hv, r1_hv, n2_hv, c2_hv, r2_hv, srs, \n",
    "                                                               min_border=200,\n",
    "                                                               max_border=200,\n",
    "                                                               #min_border=10, #test\n",
    "                                                               #max_border=10, #test\n",
    "                                                               #angles=[-9,-6, -3, 0, 3, 6, 9]) #test\n",
    "                                                               angles=[-50, -45, -40, -35, -30, -25, -20, -15,-12, -9,-6, -3, 0, 3, 6, 9, 12,15, 20, 25, 30, 35, 40, 45, 50])\n",
    "    # 3.2. Run feature tracking and pattern matching for HH\n",
    "    \n",
    "    # HH Processing\n",
    "    # Run feature tracking and plot results \n",
    "    c1_hh, r1_hh, c2_hh, r2_hh = SAR1_SAR2_drift_retrivial.run_feature_tracking(n1_hh, n2_hh, plots_dir_hh)\n",
    "    \n",
    "    #Run pattern matching and plot results\n",
    "    upm_hh, vpm_hh, apm_hh, rpm_hh, hpm_hh, ssim_hh, lon2pm_hh, lat2pm_hh = SAR1_SAR2_drift_retrivial.run_pattern_matching(plots_dir_hh, x, y, \n",
    "                                                               lon1pm, lat1pm, n1_hh, c1_hh, r1_hh, n2_hh, c2_hh, r2_hh,srs, \n",
    "                                                               min_border=200,\n",
    "                                                               max_border=200,\n",
    "                                                               #min_border=10, #test\n",
    "                                                               #max_border=10, #test\n",
    "                                                               #angles=[-9,-6, -3, 0, 3, 6, 9]) #test\n",
    "                                                               angles=[-50, -40, -35, -30, -25, -20, -15,-12, -9,-6, -3, 0, 3, 6, 9, 12,15, 20, 25, 30, 35, 40, 50 ])\n",
    "    # 3.3. Get combined drift and all textural parameters\n",
    "    \n",
    "    # Combining hh and hv results based on hessian threshold\n",
    "    upm, vpm, apm, rpm, hpm, ssim, lon2pm, lat2pm = SAR1_SAR2_drift_retrivial.combine_hh_hv(output_dir_name, x, y, upm_hh, vpm_hh, apm_hh, rpm_hh, hpm_hh, ssim_hh, lon2pm_hh, lat2pm_hh,\n",
    "                                  upm_hv, vpm_hv, apm_hv, rpm_hv, hpm_hv, ssim_hv, lon2pm_hv, lat2pm_hv)\n",
    "    # 3.4.  Get good pixel indices based on hessian and neighbor thresholds.\n",
    "    \n",
    "    #Returns:\n",
    "    #    - gpi1: Good pixel index based on hessian value\n",
    "    #    - gpi2: Good pixel index combining hessian and neighbors count \n",
    "    \n",
    "    hessian=8\n",
    "    neighbors=2\n",
    "    \n",
    "    gpi1, gpi2 = SAR1_SAR2_drift_retrivial.get_good_pixel_indices(hpm, h_threshold=hessian, neighbors_threshold=neighbors)\n",
    "    \n",
    "        \n",
    "    # Plot the filtering results\n",
    "    general_plots_path = SAR1_SAR2_drift_retrivial.plot_filter_results(output_dir_name, x, y, hpm, upm, vpm, gpi1, gpi2, hessian, neighbors)\n",
    "    \n",
    "    \n",
    "    #  Save final drift, its parameters and filtering arrays to npy files\n",
    "    save_name = 'sar_ref_drift_output'\n",
    "    sar_drift_output_path = SAR1_SAR2_drift_retrivial.save_sar_drift_results(output_dir_name, save_name,\n",
    "                                                                             upm=upm, vpm=vpm, apm=apm, rpm=rpm, \n",
    "                                                                             hpm=hpm, ssim=ssim, lon2pm=lon2pm, \n",
    "                                                                             lat2pm=lat2pm, gpi1=gpi1, gpi2=gpi2)\n",
    "    # 4. Warp SAR1 image with the reference sar drift and compare all arrays in the comparison distination domain\n",
    "    \n",
    "    # 4.1. Warp\n",
    "    # Warp SAR1 with SAR-drift compenstaion/displacement\n",
    "    good_pixels = gpi2\n",
    "    mask_pm = ~good_pixels # mask out low quality or NaN\n",
    "    s1_dst_dom_S_hv = warping_with_domain.warp_with_uv(n1_hv, n1_hv[1], mod_dom, upm, vpm, mask_pm, dst_dom)\n",
    "    s1_dst_dom_S_hh = warping_with_domain.warp_with_uv(n1_hh, n1_hh[1], mod_dom, upm, vpm, mask_pm, dst_dom)\n",
    "    \n",
    "    # Warp SAR2 to the comparison domain\n",
    "    s2_dst_dom_hv = warping_with_domain.warp(n2_hv, n2_hv[1], dst_dom)\n",
    "    s2_dst_dom_hh = warping_with_domain.warp(n2_hh, n2_hh[1], dst_dom)\n",
    "    \n",
    "    # Warp SAR1 to the comparison domain for visualisation\n",
    "    s1_dst_dom_hv = warping_with_domain.warp(n1_hv, n1_hv[1], dst_dom)\n",
    "    s1_dst_dom_hh = warping_with_domain.warp(n1_hh, n1_hh[1], dst_dom)\n",
    "    # 4.2. Plot warping results\n",
    "    warping_with_domain.plot_sar_forecast_images(general_plots_path, \n",
    "                                                 \"Forecast_with_sar_ref_drift\", \n",
    "                                                 s1_dst_dom_hv, s2_dst_dom_hv, s1_dst_dom_S_hv,\n",
    "                                                 s1_dst_dom_hh, s2_dst_dom_hh, s1_dst_dom_S_hh,\n",
    "                                                 gamma_value=1.2)\n",
    "    # 5. Calculate quality parametrs (corr, hess, ssim) for the predicted SAR2 (by calculating pattern matchin on SAR2 and SAR2_predicted)\n",
    "    \n",
    "    # 5.1. Make new nansat objects for comparison\n",
    "    \n",
    "    n_s1_predict = Nansat.from_domain(dst_dom, array = s1_dst_dom_S_hv)\n",
    "    n_s2 = Nansat.from_domain(dst_dom, array = s2_dst_dom_hv)\n",
    "    \n",
    "    # 5.2. Create directory for saving plots \n",
    "    comparison_dir = os.path.join(output_dir_name, f\"comparison_plots\")\n",
    "    try:\n",
    "        os.makedirs(comparison_dir, exist_ok=True)\n",
    "        print(f\"Successfully created {comparison_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to create {comparison_dir}. Error: {e}\")\n",
    "        \n",
    "    # Calculate realibility indexes \n",
    "    \n",
    "    # 5.4. Run feature tracking and plot results \n",
    "    c1_alg_hv, r1_alg_hv, c2_alg_hv, r2_alg_hv = SAR1_SAR2_drift_retrivial.run_feature_tracking(n_s1_predict, n_s2, comparison_dir)\n",
    "    \n",
    "    # 5.5. Run pattern matching and plot results\n",
    "    upm_alg_hv, vpm_alg_hv, apm_alg_hv, rpm_alg_hv, hpm_alg_hv, ssim_alg_hv, lon2pm_alg_hv, lat2pm_alg_hv = SAR1_SAR2_drift_retrivial.run_pattern_matching(comparison_dir, x, y, \n",
    "                                                               lon1pm, lat1pm, n_s1_predict, c1_alg_hv, r1_alg_hv, n_s2, c2_alg_hv, r2_alg_hv, srs, \n",
    "                                                               min_border=200,\n",
    "                                                               max_border=200,\n",
    "                                                               #min_border=10, #test\n",
    "                                                               #max_border=10, #test\n",
    "                                                               #angles=[-9,-6, -3, 0, 3, 6, 9]) #test\n",
    "                                                               angles=[-50, -45, -40, -35, -30, -25, -20, -15,-12, -9,-6, -3, 0, 3, 6, 9, 12,15, 20, 25, 30, 35, 40, 45, 50])\n",
    "    \n",
    "    \n",
    "    # 5.6. Save comparison results, its parameters and filtering arrays to npy files\n",
    "    save_name = 'sar_drift_forecast_quality'\n",
    "    sar_drift_output_path = SAR1_SAR2_drift_retrivial.save_sar_drift_results(comparison_dir, save_name,\n",
    "                                                                             upm=upm, vpm=vpm, apm=apm, rpm=rpm, \n",
    "                                                                             hpm=hpm, ssim=ssim, lon2pm=lon2pm, \n",
    "                                                                             lat2pm=lat2pm, gpi1=gpi1, gpi2=gpi2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c6cb90d-dec6-49fd-ac3f-810131f6c0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/experiment_data/2022-2023_48h_experiment/batch_output/20230212T080151_20230214T074531/General_plots/images_vs_domain_borders.png'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.2  Define model domain (mod_dom) for comparing drift and comparison (dst_dom) domain to compare SAR images (real and forecasted)\n",
    "\n",
    "# Prepare subset model grid for domains and pattern matching\n",
    "X_subset, Y_subset, lon_subset, lat_subset = domains_preparation.prepare_grid(n1_hv, n2_hv, srs, X, Y, lon, lat, buffer=0)\n",
    "\n",
    "# Set a model domain\n",
    "mod_res = 2500\n",
    "mod_dom = Domain(srs, f'-te {min(X_subset.data)} {min(Y_subset.data) - mod_res * 2} {max(X_subset.data) + mod_res} {max(Y_subset.data)} -tr {mod_res} {mod_res}')\n",
    "\n",
    "\n",
    "lon1pm, lat1pm = mod_dom.get_geolocation_grids()\n",
    "x, y = mod_dom.get_geolocation_grids(dst_srs=srs)\n",
    "\n",
    "# Set a comparison domain \n",
    "dst_res = 100\n",
    "dst_dom = Domain(srs, f'-te {min(X_subset.data)} {min(Y_subset.data) - dst_res * 2} {max(X_subset.data) + dst_res} {max(Y_subset.data)} -tr {dst_res} {dst_res}')\n",
    "\n",
    "domains_preparation.plot_borders(mod_dom, n1_hv, n2_hv, output_dir_name) # borders for hh and hv are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bff85ed-0d1a-49ce-aa64-0d36d85739ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dst_dom corner coordinates: (array([278603.1875, 823603.1875, 278603.1875, 823603.1875]), array([774568.375, 774568.375,  69568.375,  69568.375]))\n",
      "mod_dom corner coordinates: (array([278603.1875, 823603.1875, 278603.1875, 823603.1875]), array([774568.375, 774568.375,  69568.375,  69568.375]))\n"
     ]
    }
   ],
   "source": [
    "# Checking that domains have the same borders \n",
    "\n",
    "rows1, cols1 = dst_dom.shape()\n",
    "print(\"dst_dom corner coordinates:\", dst_dom.transform_points([0,cols1-1,0,cols1-1], [0,0,rows1-1,rows1-1], dst_srs=srs))\n",
    "\n",
    "rows1, cols1 = mod_dom.shape()\n",
    "print(\"mod_dom corner coordinates:\", mod_dom.transform_points([0,cols1-1,0,cols1-1], [0,0,rows1-1,rows1-1], dst_srs=srs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7ed0cd-218f-4ed9-b94c-4f514a30463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.   Retrieve reference drift\n",
    "# 3.1. Run feature tracking and pattern matching for HV\n",
    "\n",
    "# Run feature tracking and plot results \n",
    "c1_hv, r1_hv, c2_hv, r2_hv = SAR1_SAR2_drift_retrivial.run_feature_tracking(n1_hv, n2_hv, plots_dir_hv)\n",
    "\n",
    "#Run pattern matching and plot results\n",
    "upm_hv, vpm_hv, apm_hv, rpm_hv, hpm_hv, ssim_hv, lon2pm_hv, lat2pm_hv = SAR1_SAR2_drift_retrivial.run_pattern_matching(plots_dir_hv, x, y, \n",
    "                                                           lon1pm, lat1pm, n1_hv, c1_hv, r1_hv, n2_hv, c2_hv, r2_hv, srs, \n",
    "                                                           min_border=200,\n",
    "                                                           max_border=200,\n",
    "                                                           #min_border=10, #test\n",
    "                                                           #max_border=10, #test\n",
    "                                                           #angles=[-9,-6, -3, 0, 3, 6, 9]) #test\n",
    "                                                           angles=[-50, -45, -40, -35, -30, -25, -20, -15,-12, -9,-6, -3, 0, 3, 6, 9, 12,15, 20, 25, 30, 35, 40, 45, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77899945-d1a2-4ed9-aba2-c5b44ae8c0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key points found: 50000\n",
      "Key points found: 50000\n",
      "Domain filter: 50000 -> 43258\n",
      "Domain filter: 50000 -> 48486\n",
      "Keypoints matched 4.317245721817017\n",
      "Ratio test 0.600000 found 489 keypoints\n",
      "MaxDrift filter: 489 -> 489\n",
      "LSTSQ filter: 489 -> 481\n",
      "62% 03231.0 03182.1 04016.0 03229.0 +00.0 0.57 19.03 0.47\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/packages/2022-2023_48h_experiment/one_flow_package/./modules/sea_ice_drift/pmlib_with_ssim.py:60: RuntimeWarning: invalid value encountered in divide\n",
      "  hes = (hes - np.median(hes)) / np.std(hes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85% 02551.3 04250.4 03534.0 04466.0 +09.0 0.53 15.77 0.4398% 01837.9 04844.5 02841.0 05223.0 +12.0 0.34 7.49 0.1789% 02838.1 04475.1 03929.0 04638.0 +30.0 0.27 4.60 0.17\n",
      " Pattern matching - OK! (413 sec)\n"
     ]
    }
   ],
   "source": [
    "# 3.2. Run feature tracking and pattern matching for HH\n",
    "\n",
    "# HH Processing\n",
    "# Run feature tracking and plot results \n",
    "c1_hh, r1_hh, c2_hh, r2_hh = SAR1_SAR2_drift_retrivial.run_feature_tracking(n1_hh, n2_hh, plots_dir_hh)\n",
    "\n",
    "#Run pattern matching and plot results\n",
    "upm_hh, vpm_hh, apm_hh, rpm_hh, hpm_hh, ssim_hh, lon2pm_hh, lat2pm_hh = SAR1_SAR2_drift_retrivial.run_pattern_matching(plots_dir_hh, x, y, \n",
    "                                                           lon1pm, lat1pm, n1_hh, c1_hh, r1_hh, n2_hh, c2_hh, r2_hh,srs, \n",
    "                                                           min_border=200,\n",
    "                                                           max_border=200,\n",
    "                                                           #min_border=10, #test\n",
    "                                                           #max_border=10, #test\n",
    "                                                           #angles=[-9,-6, -3, 0, 3, 6, 9]) #test\n",
    "                                                           angles=[-50, -40, -35, -30, -25, -20, -15,-12, -9,-6, -3, 0, 3, 6, 9, 12,15, 20, 25, 30, 35, 40, 50 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e3a3f95-ea2b-4ba9-8cdf-70fc8cc6e935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3. Get combined drift and all textural parameters\n",
    "\n",
    "# Combining hh and hv results based on hessian threshold\n",
    "upm, vpm, apm, rpm, hpm, ssim, lon2pm, lat2pm = SAR1_SAR2_drift_retrivial.combine_hh_hv(output_dir_name, x, y, upm_hh, vpm_hh, apm_hh, rpm_hh, hpm_hh, ssim_hh, lon2pm_hh, lat2pm_hh,\n",
    "                              upm_hv, vpm_hv, apm_hv, rpm_hv, hpm_hv, ssim_hv, lon2pm_hv, lat2pm_hv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b77b1f2b-7af2-4f7a-9edd-3fa379dd79ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrays saved to /home/jovyan/experiment_data/2022-2023_48h_experiment/batch_output/20230212T080151_20230214T074531/sar_ref_drift_output/sar_ref_drift_output.npz\n"
     ]
    }
   ],
   "source": [
    "# 3.4.  Get good pixel indices based on hessian and neighbor thresholds.\n",
    "\n",
    "#Returns:\n",
    "#    - gpi1: Good pixel index based on hessian value\n",
    "#    - gpi2: Good pixel index combining hessian and neighbors count \n",
    "\n",
    "hessian=8\n",
    "neighbors=2\n",
    "\n",
    "gpi1, gpi2 = SAR1_SAR2_drift_retrivial.get_good_pixel_indices(hpm, h_threshold=hessian, neighbors_threshold=neighbors)\n",
    "\n",
    "    \n",
    "# Plot the filtering results\n",
    "general_plots_path = SAR1_SAR2_drift_retrivial.plot_filter_results(output_dir_name, x, y, hpm, upm, vpm, gpi1, gpi2, hessian, neighbors)\n",
    "\n",
    "\n",
    "#  Save final drift, its parameters and filtering arrays to npy files\n",
    "save_name = 'sar_ref_drift_output'\n",
    "sar_drift_output_path = SAR1_SAR2_drift_retrivial.save_sar_drift_results(output_dir_name, save_name,\n",
    "                                                                         upm=upm, vpm=vpm, apm=apm, rpm=rpm, \n",
    "                                                                         hpm=hpm, ssim=ssim, lon2pm=lon2pm, \n",
    "                                                                         lat2pm=lat2pm, gpi1=gpi1, gpi2=gpi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87367893-2094-4d09-99cd-83638b73aa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Warp SAR1 image with the reference sar drift and compare all arrays in the comparison distination domain\n",
    "\n",
    "# 4.1. Warp\n",
    "# Warp SAR1 with SAR-drift compenstaion/displacement\n",
    "good_pixels = gpi2\n",
    "mask_pm = ~good_pixels # mask out low quality or NaN\n",
    "s1_dst_dom_S_hv = warping_with_domain.warp_with_uv(n1_hv, n1_hv[1], mod_dom, upm, vpm, mask_pm, dst_dom)\n",
    "s1_dst_dom_S_hh = warping_with_domain.warp_with_uv(n1_hh, n1_hh[1], mod_dom, upm, vpm, mask_pm, dst_dom)\n",
    "\n",
    "# Warp SAR2 to the comparison domain\n",
    "s2_dst_dom_hv = warping_with_domain.warp(n2_hv, n2_hv[1], dst_dom)\n",
    "s2_dst_dom_hh = warping_with_domain.warp(n2_hh, n2_hh[1], dst_dom)\n",
    "\n",
    "# Warp SAR1 to the comparison domain for visualisation\n",
    "s1_dst_dom_hv = warping_with_domain.warp(n1_hv, n1_hv[1], dst_dom)\n",
    "s1_dst_dom_hh = warping_with_domain.warp(n1_hh, n1_hh[1], dst_dom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eda3400-b666-46b3-a7d5-c0c21fcbf6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2. Plot warping results\n",
    "warping_with_domain.plot_sar_forecast_images(general_plots_path, \n",
    "                                             \"Forecast_with_sar_ref_drift\", \n",
    "                                             s1_dst_dom_hv, s2_dst_dom_hv, s1_dst_dom_S_hv,\n",
    "                                             s1_dst_dom_hh, s2_dst_dom_hh, s1_dst_dom_S_hh,\n",
    "                                             gamma_value=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71e9ebdd-c3de-4e17-a1ed-f47151d5d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Calculate quality parametrs (corr, hess, ssim) for the predicted SAR2 (by calculating pattern matchin on SAR2 and SAR2_predicted)\n",
    "\n",
    "# 5.1. Make new nansat objects for comparison\n",
    "\n",
    "n_s1_predict = Nansat.from_domain(dst_dom, array = s1_dst_dom_S_hv)\n",
    "n_s2 = Nansat.from_domain(dst_dom, array = s2_dst_dom_hv)\n",
    "\n",
    "# 5.2. Create directory for saving plots \n",
    "comparison_dir = os.path.join(output_dir_name, f\"comparison_plots\")\n",
    "try:\n",
    "    os.makedirs(comparison_dir, exist_ok=True)\n",
    "    print(f\"Successfully created {comparison_dir}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to create {comparison_dir}. Error: {e}\")\n",
    "    \n",
    "# Calculate realibility indexes \n",
    "\n",
    "# 5.4. Run feature tracking and plot results \n",
    "c1_alg_hv, r1_alg_hv, c2_alg_hv, r2_alg_hv = SAR1_SAR2_drift_retrivial.run_feature_tracking(n_s1_predict, n_s2, comparison_dir)\n",
    "\n",
    "# 5.5. Run pattern matching and plot results\n",
    "upm_alg_hv, vpm_alg_hv, apm_alg_hv, rpm_alg_hv, hpm_alg_hv, ssim_alg_hv, lon2pm_alg_hv, lat2pm_alg_hv = SAR1_SAR2_drift_retrivial.run_pattern_matching(comparison_dir, x, y, \n",
    "                                                           lon1pm, lat1pm, n_s1_predict, c1_alg_hv, r1_alg_hv, n_s2, c2_alg_hv, r2_alg_hv, srs, \n",
    "                                                           min_border=200,\n",
    "                                                           max_border=200,\n",
    "                                                           #min_border=10, #test\n",
    "                                                           #max_border=10, #test\n",
    "                                                           #angles=[-9,-6, -3, 0, 3, 6, 9]) #test\n",
    "                                                           angles=[-50, -45, -40, -35, -30, -25, -20, -15,-12, -9,-6, -3, 0, 3, 6, 9, 12,15, 20, 25, 30, 35, 40, 45, 50])\n",
    "\n",
    "\n",
    "# 5.6. Save comparison results, its parameters and filtering arrays to npy files\n",
    "save_name = 'sar_drift_forecast_quality'\n",
    "sar_drift_output_path = SAR1_SAR2_drift_retrivial.save_sar_drift_results(comparison_dir, save_name,\n",
    "                                                                         upm=upm, vpm=vpm, apm=apm, rpm=rpm, \n",
    "                                                                         hpm=hpm, ssim=ssim, lon2pm=lon2pm, \n",
    "                                                                         lat2pm=lat2pm, gpi1=gpi1, gpi2=gpi2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
