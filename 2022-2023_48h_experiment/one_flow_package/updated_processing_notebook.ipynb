{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9429456e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./modules\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6834b5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import general modules\n",
    "from nansat import Nansat, Domain, NSR\n",
    "import os \n",
    "\n",
    "# Import temporal modules needed for testing plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Import SAR forecasting modules\n",
    "import config\n",
    "import s1_preparation\n",
    "import domains_preparation\n",
    "import SAR1_SAR2_drift_retrivial\n",
    "import warping_with_domain\n",
    "\n",
    "# Import variables\n",
    "from config import path_to_HH_files, path_to_HV_files, safe_folder \n",
    "from config import output_folder, input_folder\n",
    "from config import S1_prod_regex, S1_safe_regex\n",
    "from config import lon, lat, X, Y, proj4, srs\n",
    "\n",
    "# For cleaning up memory\n",
    "import gc\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "import cProfile\n",
    "import pstats\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28eeefbd-e6c3-4bce-bc20-4d1a0fb8b528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair 1:\n",
      "SAR1: S1A_EW_GRDM_1SDH_20230327T075355_20230327T075459_047827_05BF0B_E30B.SAFE \n",
      "timestamp: 2023-03-27 07:53:55\n",
      "SAR2: S1A_EW_GRDM_1SDH_20230329T073729_20230329T073833_047856_05C011_8100.SAFE \n",
      "timestamp: 2023-03-29 07:37:29\n"
     ]
    }
   ],
   "source": [
    "# 1. Prepare SAR pairs\n",
    "\n",
    "# Collect Sentinel SAFE objects for files in safe directory.\n",
    "safe_objects = s1_preparation.collect_sentinel_files(safe_folder, path_to_HH_files, path_to_HV_files,  S1_safe_regex, S1_prod_regex)\n",
    "\n",
    "# Get pairs of Sentinel SAFE objects where their timestamps are within 50 hours of each other.\n",
    "sar_pairs = s1_preparation.get_pairs_within_time_limit(safe_objects, hours = 50)\n",
    "\n",
    "# Print details for each pair.\n",
    "for index, pair in enumerate(sar_pairs, start=1):  # start=1 makes the index start from 1\n",
    "    print(f'Pair {index}:')\n",
    "    print(f'SAR1: {pair[0].filename} \\ntimestamp: {pair[0].timestamp}\\n'\n",
    "          f'SAR2: {pair[1].filename} \\ntimestamp: {pair[1].timestamp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb6ccdd0-3680-47e3-8348-feb283662131",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sar_pairs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m dst_dom \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Initialize to None\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Loop over all pairs and use enumerate to get an index for each pair\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, pair \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43msar_pairs\u001b[49m, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):  \u001b[38;5;66;03m# start=1 to have human-friendly indexing\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Create a Profile object\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     pr \u001b[38;5;241m=\u001b[39m cProfile\u001b[38;5;241m.\u001b[39mProfile()\n\u001b[1;32m     19\u001b[0m     pr\u001b[38;5;241m.\u001b[39menable()  \u001b[38;5;66;03m# Start profiling\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sar_pairs' is not defined"
     ]
    }
   ],
   "source": [
    "# Define mod_dom and dst_dom outside the loop\n",
    "mod_res = 2500\n",
    "mod_dom = None  # Initialize to None\n",
    "dst_res = 100\n",
    "dst_dom = None  # Initialize to None\n",
    "\n",
    "\n",
    "\n",
    "# Loop over all pairs and use enumerate to get an index for each pair\n",
    "for index, pair in enumerate(sar_pairs, start=1):  # start=1 to have human-friendly indexing\n",
    "    \n",
    "    # Create a Profile object\n",
    "    pr = cProfile.Profile()\n",
    "    pr.enable()  # Start profiling\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 2.1. Prepare nansat objects and domains for HV polarisation\n",
    "    n1_hv, n2_hv, output_dir_name, plots_dir_hv = domains_preparation.prepare_nansat_objects(\n",
    "        pair[0], pair[1], output_folder, polarisation='HV')\n",
    "    \n",
    "    # Prepare nansat objects and domains for HH polarisation\n",
    "    n1_hh, n2_hh, output_dir_name, plots_dir_hh = domains_preparation.prepare_nansat_objects(\n",
    "        pair[0], pair[1], output_folder, polarisation='HH')\n",
    "    \n",
    "\n",
    "    # Additional processing steps\n",
    "    # 2.2  Define model domain (mod_dom) for comparing drift and comparison (dst_dom) domain to compare SAR images (real and forecasted)\n",
    "    \n",
    "    '''\n",
    "    # Pick this if want create mod and comparison domain for each pair (then they can differ)\n",
    "    # Prepare subset model grid for domains and pattern matching\n",
    "    X_subset, Y_subset, lon_subset, lat_subset = domains_preparation.prepare_grid(n1_hv, n2_hv, srs, X, Y, lon, lat, buffer=0)\n",
    "    \n",
    "    # Set a model domain\n",
    "    mod_res = 2500\n",
    "    mod_dom = Domain(srs, f'-te {min(X_subset.data)} {min(Y_subset.data) - mod_res * 2} {max(X_subset.data) + mod_res} {max(Y_subset.data)} -tr {mod_res} {mod_res}')\n",
    "    \n",
    "    \n",
    "    lon1pm, lat1pm = mod_dom.get_geolocation_grids()\n",
    "    x, y = mod_dom.get_geolocation_grids(dst_srs=srs)\n",
    "    \n",
    "    \n",
    "    # Set a comparison domain \n",
    "    dst_res = 100\n",
    "    dst_dom = Domain(srs, f'-te {min(X_subset.data)} {min(Y_subset.data) - dst_res * 2} {max(X_subset.data) + dst_res} {max(Y_subset.data)} -tr {dst_res} {dst_res}')\n",
    "    '''\n",
    "    \n",
    "    # Check if mod_dom and dst_dom are None, if so, define them based on the first pair\n",
    "    if mod_dom is None:\n",
    "        X_subset, Y_subset, lon_subset, lat_subset = domains_preparation.prepare_grid(n1_hv, n2_hv, srs, X, Y, lon, lat, buffer=0)\n",
    "        mod_dom = Domain(srs, f'-te {min(X_subset.data)} {min(Y_subset.data) - mod_res * 2} {max(X_subset.data) + mod_res} {max(Y_subset.data)} -tr {mod_res} {mod_res}')\n",
    "        lon1pm, lat1pm = mod_dom.get_geolocation_grids()\n",
    "        x, y = mod_dom.get_geolocation_grids(dst_srs=srs)\n",
    "    \n",
    "    if dst_dom is None:\n",
    "        dst_dom = Domain(srs, f'-te {min(X_subset.data)} {min(Y_subset.data) - dst_res * 2} {max(X_subset.data) + dst_res} {max(Y_subset.data)} -tr {dst_res} {dst_res}')\n",
    "        \n",
    "    \n",
    "    domains_preparation.plot_borders(mod_dom, n1_hv, n2_hv, output_dir_name) # borders for hh and hv are the same\n",
    "    # Checking that domains have the same borders\n",
    "    \n",
    "    rows1, cols1 = dst_dom.shape()\n",
    "    print(\"dst_dom corner coordinates:\", dst_dom.transform_points([0,cols1-1,0,cols1-1], [0,0,rows1-1,rows1-1], dst_srs=srs))\n",
    "    \n",
    "    rows1, cols1 = mod_dom.shape()\n",
    "    print(\"mod_dom corner coordinates:\", mod_dom.transform_points([0,cols1-1,0,cols1-1], [0,0,rows1-1,rows1-1], dst_srs=srs))\n",
    "    \n",
    "    # 3.   Retrieve reference drift\n",
    "    # 3.1. Run feature tracking and pattern matching for HV\n",
    "    \n",
    "   \n",
    "    # Run feature tracking and plot results \n",
    "    c1_hv, r1_hv, c2_hv, r2_hv = SAR1_SAR2_drift_retrivial.run_feature_tracking(n1_hv, n2_hv, plots_dir_hv)\n",
    "    \n",
    "    #Run pattern matching and plot results\n",
    "    upm_hv, vpm_hv, apm_hv, rpm_hv, hpm_hv, ssim_hv, lon2pm_hv, lat2pm_hv = SAR1_SAR2_drift_retrivial.run_pattern_matching(plots_dir_hv, x, y, \n",
    "                                                               lon1pm, lat1pm, n1_hv, c1_hv, r1_hv, n2_hv, c2_hv, r2_hv, srs, \n",
    "                                                               min_border=200,\n",
    "                                                               max_border=200,\n",
    "                                                               #min_border=10, #test\n",
    "                                                               #max_border=10, #test\n",
    "                                                               #angles=[-9,-6, -3, 0, 3, 6, 9]) #test\n",
    "                                                               angles=[-50, -45, -40, -35, -30, -25, -20, -15,-12, -9,-6, -3, 0, 3, 6, 9, 12,15, 20, 25, 30, 35, 40, 45, 50])\n",
    "    # 3.2. Run feature tracking and pattern matching for HH\n",
    "    \n",
    "    # HH Processing\n",
    "    # Run feature tracking and plot results \n",
    "    c1_hh, r1_hh, c2_hh, r2_hh = SAR1_SAR2_drift_retrivial.run_feature_tracking(n1_hh, n2_hh, plots_dir_hh)\n",
    "    \n",
    "    #Run pattern matching and plot results\n",
    "    upm_hh, vpm_hh, apm_hh, rpm_hh, hpm_hh, ssim_hh, lon2pm_hh, lat2pm_hh = SAR1_SAR2_drift_retrivial.run_pattern_matching(plots_dir_hh, x, y, \n",
    "                                                               lon1pm, lat1pm, n1_hh, c1_hh, r1_hh, n2_hh, c2_hh, r2_hh,srs, \n",
    "                                                               min_border=200,\n",
    "                                                               max_border=200,\n",
    "                                                               #min_border=10, #test\n",
    "                                                               #max_border=10, #test\n",
    "                                                               #angles=[-9,-6, -3, 0, 3, 6, 9]) #test\n",
    "                                                               angles=[-50, -40, -35, -30, -25, -20, -15,-12, -9,-6, -3, 0, 3, 6, 9, 12,15, 20, 25, 30, 35, 40, 50 ])\n",
    "    \n",
    "    \n",
    "    # 3.3. Get combined drift and all textural parameters\n",
    "    \n",
    "    # Combining hh and hv results based on hessian threshold\n",
    "    upm, vpm, apm, rpm, hpm, ssim, lon2pm, lat2pm = SAR1_SAR2_drift_retrivial.combine_hh_hv(output_dir_name, x, y, upm_hh, vpm_hh, apm_hh, rpm_hh, hpm_hh, ssim_hh, lon2pm_hh, lat2pm_hh,\n",
    "                                  upm_hv, vpm_hv, apm_hv, rpm_hv, hpm_hv, ssim_hv, lon2pm_hv, lat2pm_hv)\n",
    "    # 3.4.  Get good pixel indices based on hessian and neighbor thresholds.\n",
    "    \n",
    "    #Returns:\n",
    "    #    - gpi1: Good pixel index based on hessian value\n",
    "    #    - gpi2: Good pixel index combining hessian and neighbors count \n",
    "    \n",
    "    hessian=8\n",
    "    neighbors=2\n",
    "    \n",
    "    gpi1, gpi2 = SAR1_SAR2_drift_retrivial.get_good_pixel_indices(hpm, h_threshold=hessian, neighbors_threshold=neighbors)\n",
    "    \n",
    "        \n",
    "    # Plot the filtering results\n",
    "    general_plots_path = SAR1_SAR2_drift_retrivial.plot_filter_results(output_dir_name, x, y, hpm, upm, vpm, gpi1, gpi2, hessian, neighbors)\n",
    "    \n",
    "    \n",
    "    #  Save final drift, its parameters and filtering arrays to npy files\n",
    "    save_name = 'sar_ref_drift_output'\n",
    "    sar_drift_output_path = SAR1_SAR2_drift_retrivial.save_sar_drift_results(output_dir_name, save_name,\n",
    "                                                                             upm=upm, vpm=vpm, apm=apm, rpm=rpm, \n",
    "                                                                             hpm=hpm, ssim=ssim, lon2pm=lon2pm, \n",
    "                                                                             lat2pm=lat2pm, gpi1=gpi1, gpi2=gpi2)\n",
    "    # 4. Warp SAR1 image with the reference sar drift and compare all arrays in the comparison distination domain\n",
    "    \n",
    "    # 4.1. Warp\n",
    "    # Warp SAR1 with SAR-drift compenstaion/displacement\n",
    "    good_pixels = gpi2\n",
    "    mask_pm = ~good_pixels # mask out low quality or NaN\n",
    "    s1_dst_dom_S_hv = warping_with_domain.warp_with_uv(n1_hv, n1_hv[1], mod_dom, upm, vpm, mask_pm, dst_dom)\n",
    "    s1_dst_dom_S_hh = warping_with_domain.warp_with_uv(n1_hh, n1_hh[1], mod_dom, upm, vpm, mask_pm, dst_dom)\n",
    "    \n",
    "    # Warp SAR2 to the comparison domain\n",
    "    s2_dst_dom_hv = warping_with_domain.warp(n2_hv, n2_hv[1], dst_dom)\n",
    "    s2_dst_dom_hh = warping_with_domain.warp(n2_hh, n2_hh[1], dst_dom)\n",
    "    \n",
    "    # Warp SAR1 to the comparison domain for visualisation\n",
    "    s1_dst_dom_hv = warping_with_domain.warp(n1_hv, n1_hv[1], dst_dom)\n",
    "    s1_dst_dom_hh = warping_with_domain.warp(n1_hh, n1_hh[1], dst_dom)\n",
    "    # 4.2. Plot warping results\n",
    "    warping_with_domain.plot_sar_forecast_images(general_plots_path, \n",
    "                                                 \"Forecast_with_sar_ref_drift\", \n",
    "                                                 s1_dst_dom_hv, s2_dst_dom_hv, s1_dst_dom_S_hv,\n",
    "                                                 s1_dst_dom_hh, s2_dst_dom_hh, s1_dst_dom_S_hh,\n",
    "                                                 gamma_value=1.2)\n",
    "    # 5. Calculate quality parametrs (corr, hess, ssim) for the predicted SAR2 (by calculating pattern matchin on SAR2 and SAR2_predicted)\n",
    "    \n",
    "    # 5.1. Make new nansat objects for comparison\n",
    "    \n",
    "    n_s1_predict = Nansat.from_domain(dst_dom, array = s1_dst_dom_S_hv)\n",
    "    n_s2 = Nansat.from_domain(dst_dom, array = s2_dst_dom_hv)\n",
    "    \n",
    "    # 5.2. Create directory for saving plots \n",
    "    comparison_dir = os.path.join(output_dir_name, f\"comparison_plots\")\n",
    "    try:\n",
    "        os.makedirs(comparison_dir, exist_ok=True)\n",
    "        print(f\"Successfully created {comparison_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to create {comparison_dir}. Error: {e}\")\n",
    "        \n",
    "    # Calculate realibility indexes \n",
    "    \n",
    "    \n",
    "    # 5.4. Run feature tracking and plot results \n",
    "    c1_alg_hv, r1_alg_hv, c2_alg_hv, r2_alg_hv = SAR1_SAR2_drift_retrivial.run_feature_tracking(n_s1_predict, n_s2, comparison_dir)\n",
    "    \n",
    "    # 5.5. Run pattern matching and plot results\n",
    "    upm_alg_hv, vpm_alg_hv, apm_alg_hv, rpm_alg_hv, hpm_alg_hv, ssim_alg_hv, lon2pm_alg_hv, lat2pm_alg_hv = SAR1_SAR2_drift_retrivial.run_pattern_matching(comparison_dir, x, y, \n",
    "                                                               lon1pm, lat1pm, n_s1_predict, c1_alg_hv, r1_alg_hv, n_s2, c2_alg_hv, r2_alg_hv, srs, \n",
    "                                                               min_border=200,\n",
    "                                                               max_border=200,\n",
    "                                                               #min_border=10, #test\n",
    "                                                               #max_border=10, #test\n",
    "                                                               angles=[-15,-12,-9,-6, -3, 0, 3, 6, 9, 12, 15]) #light\n",
    "                                                               #angles=[-50, -45, -40, -35, -30, -25, -20, -15,-12, -9,-6, -3, 0, 3, 6, 9, 12,15, 20, 25, 30, 35, 40, 45, 50])\n",
    "    \n",
    "    # 5.6. Save comparison results, its parameters and filtering arrays to npy files\n",
    "    save_name = 'sar_drift_forecast_quality'\n",
    "    sar_drift_output_path = SAR1_SAR2_drift_retrivial.save_sar_drift_results(comparison_dir, save_name,\n",
    "                                                                             upm=upm, vpm=vpm, apm=apm, rpm=rpm, \n",
    "                                                                             hpm=hpm, ssim=ssim, lon2pm=lon2pm, \n",
    "                                                                             lat2pm=lat2pm, gpi1=gpi1, gpi2=gpi2)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Pair {index} processed in {end_time - start_time:.2f} seconds.\")\n",
    "    \n",
    "    pr.disable()  # Stop profiling\n",
    "    s = StringIO()\n",
    "    ps = pstats.Stats(pr, stream=s).sort_stats('cumulative')\n",
    "    ps.print_stats()\n",
    "\n",
    "    # Get the profiling results as a string and print it\n",
    "    profiling_results = s.getvalue()\n",
    "    # Save the stats to a file\n",
    "    profiling_dir_path = os.path.join(output_dir_name, \"profiling\")\n",
    "    os.makedirs(profiling_dir_path, exist_ok=True)\n",
    "    save_path = os.path.join(profiling_dir_path, f\"profile_results_pair{index}.prof\")\n",
    "    print(f'profiling path is {save_path}')\n",
    "    ps.dump_stats(save_path)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7629257-75e9-4782-85b5-ce31bb449d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                    Type       Data/Info\n",
      "------------------------------------------------\n",
      "Domain                      type       <class 'nansat.domain.Domain'>\n",
      "NSR                         type       <class 'nansat.nsr.NSR'>\n",
      "Nansat                      type       <class 'nansat.nansat.Nansat'>\n",
      "S1_prod_regex               Pattern    re.compile('S1[AB]{1}_EW_<...><resolution>[0-9]{1,4})')\n",
      "S1_safe_regex               Pattern    re.compile('S1[AB]{1}_EW_<...>product_id>[0-9A-Z]{4})')\n",
      "SAR1_SAR2_drift_retrivial   module     <module 'SAR1_SAR2_drift_<...>SAR2_drift_retrivial.py'>\n",
      "StringIO                    type       <class '_io.StringIO'>\n",
      "X                           ndarray    739: 739 elems, type `float32`, 2956 bytes\n",
      "Y                           ndarray    949: 949 elems, type `float32`, 3796 bytes\n",
      "cProfile                    module     <module 'cProfile' from '<...>/python3.10/cProfile.py'>\n",
      "config                      module     <module 'config' from '/h<...>age/./modules/config.py'>\n",
      "domains_preparation         module     <module 'domains_preparat<...>/domains_preparation.py'>\n",
      "gc                          module     <module 'gc' (built-in)>\n",
      "index                       int        1\n",
      "input_folder                str        /home/jovyan/experiment_d<...>experiment/one_flow_input\n",
      "lat                         ndarray    949x739: 701311 elems, type `float64`, 5610488 bytes (5.350578308105469 Mb)\n",
      "lon                         ndarray    949x739: 701311 elems, type `float64`, 5610488 bytes (5.350578308105469 Mb)\n",
      "np                          module     <module 'numpy' from '/op<...>kages/numpy/__init__.py'>\n",
      "os                          module     <module 'os' from '/opt/c<...>da/lib/python3.10/os.py'>\n",
      "output_folder               str        /home/jovyan/experiment_d<...>eriment/test_batch_output\n",
      "pair                        tuple      n=2\n",
      "path_to_HH_files            str        /home/jovyan/experiment_d<...>ch_processing/test/HH_160\n",
      "path_to_HV_files            str        /home/jovyan/experiment_d<...>ch_processing/test/HV_160\n",
      "plt                         module     <module 'matplotlib.pyplo<...>es/matplotlib/pyplot.py'>\n",
      "proj4                       str        +proj=lcc +lat_0=77.5 +lo<...>7.5 +no_defs +R=6.371e+06\n",
      "pstats                      module     <module 'pstats' from '/o<...>ib/python3.10/pstats.py'>\n",
      "s1_preparation              module     <module 's1_preparation' <...>dules/s1_preparation.py'>\n",
      "safe_folder                 str        /home/jovyan/experiment_d<...>ment/SAR_images/safe_test\n",
      "safe_objects                list       n=2\n",
      "sar_pairs                   list       n=1\n",
      "srs                         NSR        PROJCS[\"unknown\",\\n    GE<...>  AXIS[\"Northing\",NORTH]]\n",
      "sys                         module     <module 'sys' (built-in)>\n",
      "time                        module     <module 'time' (built-in)>\n",
      "warping_with_domain         module     <module 'warping_with_dom<...>/warping_with_domain.py'>\n"
     ]
    }
   ],
   "source": [
    "#Cehck what takes thge memory\n",
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4087a2db-8367-470e-addb-ccb7bba6dfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov  8 23:56:05 2023    /home/jovyan/experiment_data/2022-2023_48h_experiment/batch_output/20221120T080155_20221122T074535/profiling/profile_results_pair1.prof\n",
      "\n",
      "         24665245 function calls (24033761 primitive calls) in 1358.218 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 3505 to 20 due to restriction <20>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        3    0.002    0.001 1154.166  384.722 /home/jovyan/packages/2022-2023_48h_experiment/one_flow_package/./modules/SAR1_SAR2_drift_retrivial.py:155(run_pattern_matching)\n",
      "        3    0.022    0.007 1133.644  377.881 /home/jovyan/packages/2022-2023_48h_experiment/one_flow_package/./modules/sea_ice_drift/pmlib_with_ssim.py:341(pattern_matching)\n",
      "       42    0.000    0.000 1121.569   26.704 /opt/conda/lib/python3.10/threading.py:582(wait)\n",
      "       42    0.001    0.000 1121.568   26.704 /opt/conda/lib/python3.10/threading.py:288(wait)\n",
      "      297 1121.567    3.776 1121.567    3.776 {method 'acquire' of '_thread.lock' objects}\n",
      "        3    0.000    0.000 1121.544  373.848 /opt/conda/lib/python3.10/multiprocessing/pool.py:359(map)\n",
      "        3    0.000    0.000 1121.543  373.848 /opt/conda/lib/python3.10/multiprocessing/pool.py:764(get)\n",
      "        3    0.000    0.000 1121.543  373.848 /opt/conda/lib/python3.10/multiprocessing/pool.py:761(wait)\n",
      "        2    0.018    0.009  108.903   54.451 /home/jovyan/packages/2022-2023_48h_experiment/one_flow_package/./modules/domains_preparation.py:22(prepare_nansat_objects)\n",
      "        4    0.983    0.246  100.280   25.070 /opt/conda/lib/python3.10/site-packages/sea_ice_drift-0.7.1-py3.10.egg/sea_ice_drift/lib.py:256(get_n)\n",
      "       33    0.076    0.002   73.099    2.215 /opt/conda/lib/python3.10/site-packages/nansat/nansat.py:161(__getitem__)\n",
      "       33    0.000    0.000   70.556    2.138 /opt/conda/lib/python3.10/site-packages/GDAL-3.5.0-py3.10-linux-x86_64.egg/osgeo/gdal.py:3735(ReadAsArray)\n",
      "       33    0.001    0.000   70.551    2.138 /opt/conda/lib/python3.10/site-packages/GDAL-3.5.0-py3.10-linux-x86_64.egg/osgeo/gdal_array.py:395(BandReadAsArray)\n",
      "       33    0.000    0.000   70.549    2.138 /opt/conda/lib/python3.10/site-packages/GDAL-3.5.0-py3.10-linux-x86_64.egg/osgeo/gdal_array.py:109(BandRasterIONumPy)\n",
      "       33   70.548    2.138   70.548    2.138 {built-in method osgeo._gdal_array.BandRasterIONumPy}\n",
      "       23    0.000    0.000   58.814    2.557 /home/jovyan/.local/lib/python3.10/site-packages/matplotlib/figure.py:2923(savefig)\n",
      "       23    0.003    0.000   58.813    2.557 /home/jovyan/.local/lib/python3.10/site-packages/matplotlib/backend_bases.py:2192(print_figure)\n",
      "        3    0.008    0.003   42.851   14.284 /home/jovyan/packages/2022-2023_48h_experiment/one_flow_package/./modules/SAR1_SAR2_drift_retrivial.py:30(run_feature_tracking)\n",
      "  420/264    0.002    0.000   36.102    0.137 /home/jovyan/.local/lib/python3.10/site-packages/matplotlib/_api/deprecation.py:384(wrapper)\n",
      "       46    0.002    0.000   35.996    0.783 /home/jovyan/.local/lib/python3.10/site-packages/matplotlib/backend_bases.py:1595(wrapper)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f7ca6f90910>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = pstats.Stats( \"/home/jovyan/experiment_data/2022-2023_48h_experiment/batch_output/20221120T080155_20221122T074535/profiling/profile_results_pair1.prof\")\n",
    "\n",
    "stats.sort_stats(\"cumulative\")\n",
    "stats.print_stats(20)  # Print the top 10 functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67469bb-2098-4ad6-9748-e39ad479d8ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
